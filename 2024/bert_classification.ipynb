{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon Andersen\\miniconda3\\envs\\BigData\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# TensorFlow and transformers\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFAutoModelForSequenceClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(data, idx, target_column, symbols_per_line=100):\n",
    "    \"\"\"\n",
    "    Print a row of a DataFrame with word wrapping\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        The DataFrame containing the data to be printed\n",
    "    idx : int\n",
    "        The index of the row to be printed\n",
    "    target_column : str\n",
    "        The name of the column to be printed\n",
    "    symbols_per_line : int\n",
    "        The number of symbols per line at which to wrap the text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        \n",
    "    \"\"\"\n",
    "    value = str(data[target_column].iloc[idx])\n",
    "\n",
    "    # Remove excess spaces\n",
    "    value = ' '.join(value.split())\n",
    "    \n",
    "    # Wrap text while respecting word boundaries\n",
    "    wrapped_value = textwrap.fill(value, width=symbols_per_line)\n",
    "    \n",
    "    print(wrapped_value)\n",
    "    return\n",
    "\n",
    "def print_list(list, elements_per_line=10):\n",
    "    \"\"\"\n",
    "    Print a list with a specified number of elements per line\n",
    "    \"\"\"\n",
    "\n",
    "    list_range = range(0, len(list), elements_per_line)\n",
    "\n",
    "    for i in list_range:\n",
    "        print(*list[i:i+elements_per_line])\n",
    "    return\n",
    "\n",
    "# Define a function to find unique words in a text\n",
    "def find_unique_words(text, word_list):\n",
    "    \"\"\"\n",
    "    Find unique words in a text. Append the unique words to a list.\n",
    "    \"\"\"\n",
    "    for word in text.split():\n",
    "        if word not in word_list:\n",
    "            word_list.append(word)\n",
    "    return\n",
    "\n",
    "# print table summary with total samples in each dataset, positive samples, and negative samples\n",
    "def pretty_print_info_table(labels_train, labels_test, validation=False):\n",
    "\n",
    "    val_str = 'Val.' if validation else 'Test'\n",
    "    data_for_table = {\n",
    "        'train': {\n",
    "            'total': len(labels_train),\n",
    "            'pos': np.sum(labels_train),\n",
    "            'neg': len(labels_train) - np.sum(labels_train)\n",
    "        },\n",
    "        'test': {\n",
    "            'total': len(labels_test),\n",
    "            'pos': np.sum(labels_test),\n",
    "            'neg': len(labels_test) - np.sum(labels_test)\n",
    "        }\n",
    "    }\n",
    "    data_for_table['total'] = {\n",
    "        'total': data_for_table['train']['total'] + data_for_table['test']['total'],\n",
    "        'pos': data_for_table['train']['pos'] + data_for_table['test']['pos'],\n",
    "        'neg': data_for_table['train']['neg'] + data_for_table['test']['neg']\n",
    "    }\n",
    "\n",
    "    print(\"\"\"\n",
    "    Info table:\n",
    "    +----------------+---------+---------+-------+\n",
    "    |                | Training| {}    | Total\n",
    "    +----------------+---------+---------+-------+\n",
    "    | Total samples  | {:7d} | {:7d} | {:7d} |\n",
    "    | Pos. samples   | {:7d} | {:7d} | {:7d} |  (AI generated)\n",
    "    | Neg. samples   | {:7d} | {:7d} | {:7d} |  (Human written)\n",
    "    \"\"\".format(\n",
    "        val_str,\n",
    "        data_for_table['train']['total'],\n",
    "        data_for_table['test']['total'],\n",
    "        data_for_table['total']['total'],\n",
    "        data_for_table['train']['pos'],\n",
    "        data_for_table['test']['pos'],\n",
    "        data_for_table['total']['pos'],\n",
    "        data_for_table['train']['neg'],\n",
    "        data_for_table['test']['neg'],\n",
    "        data_for_table['total']['neg'],\n",
    "        \n",
    "        ))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 = AI-generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Info table:\n",
      "    +----------------+---------+---------+-------+\n",
      "    |                | Training| Test    | Total\n",
      "    +----------------+---------+---------+-------+\n",
      "    | Total samples  |    2854 |     215 |    3069 |\n",
      "    | Pos. samples   |    1321 |     103 |    1424 |  (AI generated)\n",
      "    | Neg. samples   |    1533 |     112 |    1645 |  (Human written)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('ai_human_training_data.csv', index_col=0)\n",
    "data['label'] = data['label'].astype(int)\n",
    "data['text'] = data['text'].astype(str)\n",
    "\n",
    "data_test = pd.read_csv('ai_human_test_data.csv', index_col=0)\n",
    "data_test['label'] = data_test['label'].astype(int)\n",
    "\n",
    "pretty_print_info_table(data.label, data_test.label, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    print(\"AI-generated text? \", bool(data['label'].iloc[i]))\n",
    "    print(\"Text:\")\n",
    "    print_row(data, i, 'text', symbols_per_line=100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Info table:\n",
      "    +----------------+---------+---------+-------+\n",
      "    |                | Training| Val.    | Total\n",
      "    +----------------+---------+---------+-------+\n",
      "    | Total samples  |    2283 |     571 |    2854 |\n",
      "    | Pos. samples   |    1062 |     259 |    1321 |  (AI generated)\n",
      "    | Neg. samples   |    1221 |     312 |    1533 |  (Human written)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "test_texts = data_test['text'].astype(str)\n",
    "test_labels = data_test['label'].astype(int)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['text'], data['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pretty_print_info_table(train_labels, val_labels, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-multilingual-cased'\n",
    "model_name = 'bert-base-uncased'\n",
    "max_length_of_input = 256\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Tokenize the text inputs for BERT\n",
    "def tokenize_texts(texts, max_len=max_length_of_input):\n",
    "    return tokenizer(\n",
    "        texts.tolist(), \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=max_len, \n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model for binary classification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to TensorFlow format\n",
    "train_labels_tf = tf.convert_to_tensor(train_labels.values)\n",
    "val_labels_tf = tf.convert_to_tensor(val_labels.values)\n",
    "test_labels_tf = tf.convert_to_tensor(test_labels.values)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_encodings['input_ids'],\n",
    "    train_labels_tf,\n",
    "    validation_data=(val_encodings['input_ids'], val_labels_tf),\n",
    "    epochs=1,  \n",
    "    batch_size=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(test_labels, predictions)\n\u001b[1;32m----> 7\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, report)\n",
      "File \u001b[1;32mc:\\Users\\Simon Andersen\\miniconda3\\envs\\BigData\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Simon Andersen\\miniconda3\\envs\\BigData\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2561\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2555\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2557\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2558\u001b[0m             )\n\u001b[0;32m   2559\u001b[0m         )\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2564\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2565\u001b[0m         )\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "logits = model.predict(test_encodings['input_ids']).logits\n",
    "predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "report = classification_report(test_labels, predictions, target_names=['AI', 'Human'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
