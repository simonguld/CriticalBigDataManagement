{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using large language models\n",
    "\n",
    "\n",
    "### Goal: \n",
    "\n",
    "Given a bunch of text snippets written by either AI or a human, the goal is to post-train a large language model and make it accurately predict whether a text snippet is AI-generated or not.\n",
    "\n",
    "\n",
    "\n",
    "******************\n",
    "$\\textit{Author:}$ Simon Guldager \\\n",
    "$\\textit{Date:}$ 1-10-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon Andersen\\miniconda3\\envs\\BigData\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# TensorFlow and transformers\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(data, idx, target_column, symbols_per_line=100, max_lines = None):\n",
    "    \"\"\"\n",
    "    Print a row of a DataFrame with word wrapping\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        The DataFrame containing the data to be printed\n",
    "    idx : int\n",
    "        The index of the row to be printed\n",
    "    target_column : str\n",
    "        The name of the column to be printed\n",
    "    symbols_per_line : int\n",
    "        The number of symbols per line at which to wrap the text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        \n",
    "    \"\"\"\n",
    "    value = str(data[target_column].iloc[idx])\n",
    "\n",
    "    # Remove excess spaces\n",
    "    value = ' '.join(value.split())\n",
    "    \n",
    "    # Wrap text while respecting word boundaries\n",
    "    wrapped_value = textwrap.fill(value, width=symbols_per_line)\n",
    "\n",
    "    if max_lines is not None:\n",
    "        wrapped_value = '\\n'.join(wrapped_value.split('\\n')[:max_lines])\n",
    "    \n",
    "    print(wrapped_value)\n",
    "    return\n",
    "\n",
    "def print_list(list, elements_per_line=10):\n",
    "    \"\"\"\n",
    "    Print a list with a specified number of elements per line\n",
    "    \"\"\"\n",
    "\n",
    "    list_range = range(0, len(list), elements_per_line)\n",
    "\n",
    "    for i in list_range:\n",
    "        print(*list[i:i+elements_per_line])\n",
    "    return\n",
    "\n",
    "# Define a function to find unique words in a text\n",
    "def find_unique_words(text, word_list):\n",
    "    \"\"\"\n",
    "    Find unique words in a text. Append the unique words to a list.\n",
    "    \"\"\"\n",
    "    for word in text.split():\n",
    "        if word not in word_list:\n",
    "            word_list.append(word)\n",
    "    return\n",
    "\n",
    "# print table summary with total samples in each dataset, positive samples, and negative samples\n",
    "def pretty_print_info_table(labels_train, labels_test, validation=False):\n",
    "    \"\"\"  \n",
    "    This function was made by Anton Golles.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    val_str = 'Val.' if validation else 'Test'\n",
    "    data_for_table = {\n",
    "        'train': {\n",
    "            'total': len(labels_train),\n",
    "            'pos': np.sum(labels_train),\n",
    "            'neg': len(labels_train) - np.sum(labels_train)\n",
    "        },\n",
    "        'test': {\n",
    "            'total': len(labels_test),\n",
    "            'pos': np.sum(labels_test),\n",
    "            'neg': len(labels_test) - np.sum(labels_test)\n",
    "        }\n",
    "    }\n",
    "    data_for_table['total'] = {\n",
    "        'total': data_for_table['train']['total'] + data_for_table['test']['total'],\n",
    "        'pos': data_for_table['train']['pos'] + data_for_table['test']['pos'],\n",
    "        'neg': data_for_table['train']['neg'] + data_for_table['test']['neg']\n",
    "    }\n",
    "\n",
    "    print(\"\"\"\n",
    "    Info table:\n",
    "    +----------------+---------+---------+-------+\n",
    "    |                | Training| {}    | Total\n",
    "    +----------------+---------+---------+-------+\n",
    "    | Total samples  | {:7d} | {:7d} | {:7d} |\n",
    "    | Pos. samples   | {:7d} | {:7d} | {:7d} |  (AI generated)\n",
    "    | Neg. samples   | {:7d} | {:7d} | {:7d} |  (Human written)\n",
    "    \"\"\".format(\n",
    "        val_str,\n",
    "        data_for_table['train']['total'],\n",
    "        data_for_table['test']['total'],\n",
    "        data_for_table['total']['total'],\n",
    "        data_for_table['train']['pos'],\n",
    "        data_for_table['test']['pos'],\n",
    "        data_for_table['total']['pos'],\n",
    "        data_for_table['train']['neg'],\n",
    "        data_for_table['test']['neg'],\n",
    "        data_for_table['total']['neg'],\n",
    "        \n",
    "        ))\n",
    "    return\n",
    "\n",
    "def plot_classificiation_results(history):\n",
    "\n",
    "    # make a list of the train and val metrics\n",
    "    metrics = list(history.history.keys())\n",
    "    \n",
    "    # make lists of train and val metrics\n",
    "    val_metrics = [entry for entry in metrics if entry.startswith('val_')]\n",
    "    train_metrics = [entry for entry in metrics if not entry.startswith('val_')]\n",
    "\n",
    "    # the number of metrics to plot\n",
    "    Nmetrics = len(val_metrics)\n",
    "    width = 6 * Nmetrics\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = Nmetrics, figsize=(width, 6))\n",
    "\n",
    "    # plot the train and val results for each metric\n",
    "    for i, axx in enumerate(ax):\n",
    "        ax[i].plot(history.history[train_metrics[i]], label='train', alpha = 0.7)  \n",
    "        ax[i].plot(history.history[val_metrics[i]], label='validation', alpha = 0.7)\n",
    "        ax[i].set_ylabel(f'{train_metrics[i].capitalize()}')\n",
    "        ax[i].set_xlabel('Epoch')\n",
    "        ax[i].legend(loc='best')\n",
    "    fig.tight_layout()\n",
    "    return fig, ax \n",
    "\n",
    "def evaluate_binary_classification_results(model, X_train, y_train, X_val, y_val, X_test = None, y_test = None,\\\n",
    "                                           metrics = [accuracy_score], metric_names = ['Accuracy']):\n",
    "    \n",
    "    # make predictions\n",
    "    y_pred_train = model.predict(X_train, verbose = 0)   \n",
    "    y_pred_val = model.predict(X_val, verbose = 0)\n",
    "\n",
    "    # if test data is provided, make predictions\n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_pred_test =  model.predict(X_test, verbose = 0)\n",
    "\n",
    "    # calculate metrics\n",
    "    for metric, metric_name in zip(metrics, metric_names):\n",
    "        metric(y_train, y_pred_train.round())\n",
    "        print(f'{metric_name} on training data: {metric(y_train, y_pred_train.round()):.3f}')\n",
    "        print(f'{metric_name} on validation data: {metric(y_val, y_pred_val.round()):.3f}')\n",
    "        if X_test is not None and y_test is not None:\n",
    "            print(f'{metric_name} on test data: {metric(y_test, y_pred_test.round()):.3f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Read the data and have a look.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retsmedicinere har forgæves forsøgt at finde u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Som politiker er jeg meget opmærksom på vigtig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Som en enkeltmandsvirksomhed har jeg fleksible...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Det er simpelthen for at kunne levere de ord...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optræden af høje tindinger med årene er en nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Retsmedicinere har forgæves forsøgt at finde u...      0\n",
       "1  Som politiker er jeg meget opmærksom på vigtig...      1\n",
       "2  Som en enkeltmandsvirksomhed har jeg fleksible...      1\n",
       "3  - Det er simpelthen for at kunne levere de ord...      0\n",
       "4  Optræden af høje tindinger med årene er en nat...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ai_human_training_data.csv', index_col=0)\n",
    "data['label'] = data['label'].astype(int)\n",
    "data['text'] = data['text'].astype(str)\n",
    "\n",
    "# make a copy of the original data\n",
    "data_orig = data.copy()\n",
    "\n",
    "\n",
    "print('Data shape:', data.shape)\n",
    "# label = 1 for AI generated text, label = 0 for human written text\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows of the data\n",
    "for i in range(0, 5):\n",
    "    print(\"AI-generated text? \", bool(data['label'].iloc[i]))\n",
    "    print(\"Text:\")\n",
    "    print_row(data, i, 'text', symbols_per_line=100)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Decide which model to use and download model and tokenizer.\n",
    "\n",
    "We are going to use the multilingual BERT, which has been trained on >100 languages incl. Danish\n",
    "\n",
    "For other models, see https://huggingface.co/transformers/v3.0.2/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# choose model\n",
    "model_name = 'bert-base-multilingual-cased'\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "# Load pre-trained BERT model for binary classification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Split data into training, validation and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Info table:\n",
      "    +----------------+---------+---------+-------+\n",
      "    |                | Training| Val.    | Total\n",
      "    +----------------+---------+---------+-------+\n",
      "    | Total samples  |     768 |     192 |     960 |\n",
      "    | Pos. samples   |     364 |      95 |     459 |  (AI generated)\n",
      "    | Neg. samples   |     404 |      97 |     501 |  (Human written)\n",
      "    \n",
      "\n",
      "    Info table:\n",
      "    +----------------+---------+---------+-------+\n",
      "    |                | Training| Test    | Total\n",
      "    +----------------+---------+---------+-------+\n",
      "    | Total samples  |     768 |     240 |    1008 |\n",
      "    | Pos. samples   |     364 |     114 |     478 |  (AI generated)\n",
      "    | Neg. samples   |     404 |     126 |     530 |  (Human written)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# it takes quite a while to post-train the model, so we will use a subset of the data\n",
    "use_all_samples = False\n",
    "# number of samples to use\n",
    "Nsamples = 1200\n",
    "\n",
    "# only use a subset of the data if use_all_samples is False\n",
    "if not use_all_samples:\n",
    "    data = data_orig.copy()\n",
    "    data = data.sample(Nsamples, random_state=42)\n",
    "    \n",
    "# Split data into training/validation and test sets\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(\n",
    "    data['text'], data['label'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "# Split training/validation data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_val_texts, train_val_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "pretty_print_info_table(train_labels, val_labels, validation=True)\n",
    "pretty_print_info_table(train_labels, test_labels, validation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Tokenize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum length of the input text (number of tokens). \n",
    "# Increasing this value will increase the computational cost, but may improve model performance.\n",
    "max_length_of_input = 128\n",
    "\n",
    "# Tokenize the text inputs for BERT\n",
    "def tokenize_texts(texts, max_len=max_length_of_input):\n",
    "    return tokenizer(\n",
    "        texts.tolist(), \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=max_len, \n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Compile and post-train the model\n",
    "\n",
    "NB: \n",
    "* It takes a while, so we keep the number of epochs small for the purpose of this exercise. \n",
    "* A large batch size takes a lot of RAM. You might consider looking at your memory usage during training to see how much you can crank it up (thus making training faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16/16 [==============================] - 602s 36s/step - loss: 0.6185 - accuracy: 0.6432 - val_loss: 0.5506 - val_accuracy: 0.7448\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 573s 36s/step - loss: 0.4795 - accuracy: 0.7891 - val_loss: 0.4852 - val_accuracy: 0.7917\n"
     ]
    }
   ],
   "source": [
    "# set the central parameters for compiling and training\n",
    "learning_rate = 2e-5\n",
    "epochs = 2\n",
    "batch_size = 48\n",
    "\n",
    "# Convert labels to TensorFlow format\n",
    "train_labels_tf = tf.convert_to_tensor(train_labels.values)\n",
    "val_labels_tf = tf.convert_to_tensor(val_labels.values)\n",
    "test_labels_tf = tf.convert_to_tensor(test_labels.values)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_encodings['input_ids'],\n",
    "    train_labels_tf,\n",
    "    validation_data=(val_encodings['input_ids'], val_labels_tf),\n",
    "    epochs=epochs,  \n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Evaluate your model on the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 43s 7s/step\n",
      "\n",
      "Val. Accuracy: 0.792\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.83      0.74      0.78        97\n",
      "       Human       0.76      0.84      0.80        95\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.79      0.79      0.79       192\n",
      "weighted avg       0.80      0.79      0.79       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "logits = model.predict(val_encodings['input_ids']).logits\n",
    "predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(val_labels, predictions)\n",
    "report = classification_report(val_labels, predictions, target_names=['AI', 'Human'])\n",
    "\n",
    "print(f\"\\nVal. Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final step: Once you have completely finished training and evaluating your model, see how well it generalizes by testing it on the unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 59s 7s/step\n",
      "\n",
      "Test accuracy: 0.800\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.88      0.71      0.79       126\n",
      "       Human       0.74      0.89      0.81       114\n",
      "\n",
      "    accuracy                           0.80       240\n",
      "   macro avg       0.81      0.80      0.80       240\n",
      "weighted avg       0.81      0.80      0.80       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "logits = model.predict(test_encodings['input_ids']).logits\n",
    "predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "report = classification_report(test_labels, predictions, target_names=['AI', 'Human'])\n",
    "\n",
    "print(f\"\\nTest accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************\n",
    "\n",
    "# Exercises\n",
    "\n",
    "### Exercise 1: \n",
    "\n",
    "Go through this notebook step by step and make sure you understand what we do and why\n",
    "\n",
    "### Exercise 2: \n",
    "\n",
    "Can you tell which texts are AI-generated? Try it by running the cell below (and then type in 1 for AI and 0 for human, and enter to see a new text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntexts = 15\n",
    "\n",
    "# choose Ntexts random indices\n",
    "random_indices = np.random.choice(data.shape[0], Ntexts, replace=False)\n",
    "\n",
    "# get the actual labels\n",
    "true_labels = data['label'].iloc[random_indices].values\n",
    "# make a list to hold user guesses\n",
    "your_guesses = []\n",
    "\n",
    "# print the texts corresponding to the random indices, and make the user guess if the text is AI-generated or human-written\n",
    "for i, idx in enumerate(random_indices):\n",
    "    print(f\"AI-generated text? Text {i+1}/{Ntexts}\")\n",
    "    print_row(data, idx, 'text', symbols_per_line=100, max_lines=5)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    guess = input(\"1 if AI-generated, 0 if human-written: \")\n",
    "    \n",
    "    # keep asking until the input is valid\n",
    "    while guess not in ['0', '1']:\n",
    "        guess = input(\"Invalid input. Please enter 1 if AI-generated, 0 if human-written: \")\n",
    "\n",
    "    your_guesses.append(int(guess))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(true_labels, np.array(your_guesses))\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Congratulations! Your accuracy was: {accuracy * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 3: How accurate can you make your model?\n",
    "\n",
    "The parameters used so far have been chosen simply to make training fast, and there is a lot of room for improvement! \n",
    "\n",
    "Try getting as high an accurary as possible by making adjustments and tweaks as you see fit.\n",
    "\n",
    "$\\textit{You might consider}$:\n",
    "* changing the maximum allowed input length (i.e. maximum number of tokens in a text) before tokenization. We used max_length_of_input = 32 in the tokenization step, meaning that the model only trains the first 32 words/tokens of each text.\n",
    "* increasing the number of texts (we only use 600 now, but there are 2854 in the CSV)\n",
    "* increasing the number of epochs (we use just 1!)\n",
    "* increasing the batch size (if your RAM can handle it)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
